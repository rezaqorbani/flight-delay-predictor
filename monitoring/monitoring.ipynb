{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reza/dev/repos/flight-delay-predictor/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import hopsworks\n",
    "import joblib\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "\n",
    "import dataframe_image as dfi\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.output = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/197786\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Downloading model artifact (0 dirs, 1 files)... DONE\r"
     ]
    }
   ],
   "source": [
    "project = hopsworks.login()\n",
    "fs = project.get_feature_store()\n",
    "\n",
    "mr = project.get_model_registry()\n",
    "model = mr.get_model(\"flight_delay_model\", version=1)\n",
    "model_dir = model.download()\n",
    "model = joblib.load(model_dir + \"/flight_delay_model.pkl\")\n",
    "\n",
    "batch_feature_view = fs.get_feature_view(name=\"flight_data_v2\", version=1)\n",
    "\n",
    "batch_feature_group = fs.get_feature_group(name=\"flight_data_v2\", version=1)\n",
    "query = batch_feature_group.select_all()\n",
    "query_feature_view = fs.get_or_create_feature_view(\n",
    "    name=\"flight_data_v2\",\n",
    "    version=1,\n",
    "    description=\"Read from Flight Delay dataset\",\n",
    "    labels=[\"dep_delay_new\"],\n",
    "    query=query,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using ArrowFlight (36.69s) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VersionWarning: Incremented version to `10`.\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = query_feature_view.train_test_split(test_size=0.2)\n",
    "scaler = StandardScaler()\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "X_train_scaled = scaler.fit_transform(X_train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using ArrowFlight (36.82s) \n",
      "Delay_predicted: 7.465226173400879\n",
      "Finished: Reading data from Hopsworks, using ArrowFlight (35.00s) \n",
      "Delay_actual: 0.0\n",
      "MSE: 55.72960182002953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 1/1 | Elapsed Time: 00:06 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: flight_delay_predictions_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/197786/jobs/named/flight_delay_predictions_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<hsfs.core.job.Job at 0x7fe82db27f40>, None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_data = batch_feature_view.get_batch_data()\n",
    "batch_data = torch.tensor(batch_data.values, dtype=torch.float32)\n",
    "batch_data = scaler.transform(batch_data)\n",
    "batch_data = torch.tensor(batch_data, dtype=torch.float32)\n",
    "\n",
    "y_pred = model(batch_data)\n",
    "\n",
    "offset = 1\n",
    "pred = y_pred[- offset]\n",
    "pred = float(pred)\n",
    "\n",
    "print(\"Delay_predicted: \" + str(pred))\n",
    "df = batch_feature_group.read()\n",
    "\n",
    "label = df.iloc[-offset][\"dep_delay_new\"]\n",
    "label = float(label)\n",
    "print(\"Delay_actual: \" + str(label))\n",
    "\n",
    "\n",
    "loss = (pred - label) ** 2\n",
    "print(\"MSE: \" + str(loss))\n",
    "\n",
    "monitor_fg = fs.get_or_create_feature_group(\n",
    "    name=\"flight_delay_predictions\",\n",
    "    version=1,\n",
    "    primary_key=[\n",
    "        \"datetime\",\n",
    "    ],\n",
    "    description=\"Flight delay Prediction/Outcome Monitoring\",\n",
    ")\n",
    "\n",
    "now = datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "data = {\n",
    "    \"datetime\": [now],\n",
    "    \"prediction\": [pred],\n",
    "    \"label\": [label],\n",
    "    \"mse\": [loss],\n",
    "}\n",
    "\n",
    "monitor_df = pd.DataFrame(data)\n",
    "monitor_fg.insert(monitor_df, write_options={\"wait_for_job\": False}) # set this to True if you want to run it faster (async) but you will not be able to run the next cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history_df = monitor_fg.read()\n",
    "# history_df = pd.concat([history_df, monitor_df])\n",
    "\n",
    "# df_recent = history_df.tail(4)\n",
    "# dfi.export(df_recent, \"./df_recent.png\", table_conversion=\"matplotlib\")\n",
    "# # dataset_api.upload(\"./df_recent.png\", \"Resources/images\", overwrite=True)\n",
    "\n",
    "# predictions = history_df[[\"prediction\"]]\n",
    "# labels = history_df[[\"label\"]]\n",
    "# current_mse = history_df[[\"mse\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
